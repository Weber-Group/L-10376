{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e96dfc5-29ed-446a-a6e1-2eeea622a680",
   "metadata": {},
   "source": [
    "# Nonlinear Analysis Notebook\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9886b0-7ede-4fe4-aa96-98e8256b167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import os\n",
    "import re\n",
    "from utils import *\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc2ce4-afce-4e01-9218-c45202be5c12",
   "metadata": {},
   "source": [
    "# Load the data into defined variables\n",
    "#### note if there is some error loading a key, then comment it out and try to load data. \n",
    "#### sometimes keys of a data parameter may be saved with different name, print out all keys to figure out the required key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031731b0-8be2-48b6-8628-f58ca77c6f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /sdf/data/lcls/ds/cxi/cxil1037623/results/davidjr/cxil1037623_Run0003.h5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/sdf/data/lcls/ds/cxi/cxil1037623/results/davidjr/cxil1037623_Run0003.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m\n\u001b[1;32m     28\u001b[0m keys_to_check \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserDataCfg/jungfrau4M/azav_mask0__azav_mask0_q\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserDataCfg/jungfrau4M/azav_mask1__azav_mask1_q\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserDataCfg/jungfrau4M/azav_mask0__azav_mask0_idxq\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserDataCfg/jungfrau4M/z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     43\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserDataCfg/jungfrau4M/cmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Load the data in\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcombineRuns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunNumbers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_combine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_sum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# this is the function to load the data with defined keys\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Filtered Data\u001b[39;00m\n\u001b[1;32m     48\u001b[0m azavFiltered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjungfrau4M/azav_mask0_azav\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# I(q) : 1D azimuthal average of signals in each q bin\u001b[39;00m\n",
      "File \u001b[0;32m~/CXI/L-10376/utils.py:147\u001b[0m, in \u001b[0;36mcombineRuns\u001b[0;34m(runNumbers, folder, keys_to_combine, keys_to_sum, keys_to_check, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Run\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunNumToString(runNumber)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    148\u001b[0m     get_leaves(f,data,verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    149\u001b[0m     data_array\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[0;32m/sdf/group/lcls/ds/ana/sw/conda1/inst/envs/ana-4.0.65-py3/lib/python3.9/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/sdf/group/lcls/ds/ana/sw/conda1/inst/envs/ana-4.0.65-py3/lib/python3.9/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/sdf/data/lcls/ds/cxi/cxil1037623/results/davidjr/cxil1037623_Run0003.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "runNumbers = [3]  # enter the run numbers to be loaded\n",
    "folder = '/sdf/data/lcls/ds/cxi/cxil1037623/hdf5/smalldata/' # insert here the directory path where .h5 files are stored\n",
    "###############################################\n",
    "# (1) keys_to_combine: some keys loaded for each shot & stored per shot \n",
    "# (2) keys_to_sum: some keys loaded per each run and added \n",
    "# (3) keys_to_check : check if some keys exits and have same values in all runs and load these keys \n",
    "keys_to_combine = ['jungfrau4M/azav_mask0_azav', # Unfiltered\n",
    "                   'jungfrau4M/azav_mask1_azav', # Filtered\n",
    "                   'ipm_dg2/sum',\n",
    "                    #'ipm_dg3/sum',\n",
    "                   #'ipm_hfx_dg2/sum',\n",
    "                   'gas_detector/f_11_ENRC',\n",
    "                   'ebeam/photon_energy',\n",
    "                   'evr/code_183',\n",
    "                   'evr/code_137',\n",
    "                   'evr/code_141',\n",
    "                   'lightStatus/xray',\n",
    "                  #'CXI-DG2-BMMON-WF/cxi_dg2_bmmon_wf_rebin_data',\n",
    "                  'jungfrau4M/Full_thres_sum',\n",
    "                  'feeBld/hproj',\n",
    "                  'lightStatus/laser',\n",
    "                  'dg2_traces']\n",
    "\n",
    "keys_to_sum = ['Sums/jungfrau4M_calib']\n",
    "#               'Sums/jungfrau4M_calib_thresADU1']\n",
    "\n",
    "keys_to_check = ['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_q',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_q',\n",
    "                 'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_idxq',\n",
    "                 'UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_idxq',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_qbin',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_qbin',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_qbins',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_qbins',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_userMask',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_userMask',\n",
    "                'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_matrix_q', # This are only needed once\n",
    "                'UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_matrix_phi', # This are only needed once\n",
    "                'UserDataCfg/jungfrau4M/x',\n",
    "                'UserDataCfg/jungfrau4M/y',\n",
    "                'UserDataCfg/jungfrau4M/z',\n",
    "                'UserDataCfg/jungfrau4M/cmask']\n",
    "# Load the data in\n",
    "data = combineRuns(runNumbers, folder, keys_to_combine, keys_to_sum, keys_to_check, verbose=False)  # this is the function to load the data with defined keys\n",
    "\n",
    "# Filtered Data\n",
    "azavFiltered = np.squeeze(data['jungfrau4M/azav_mask0_azav']) # I(q) : 1D azimuthal average of signals in each q bin\n",
    "qbinFiltered = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_qbin'] # q bin-size\n",
    "qFiltered = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_q'] # q bins \n",
    "qbinsFiltered = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_qbins'] # q bins\n",
    "userMaskFiltered = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_userMask'].astype(bool) # User mask for this region\n",
    "qbinSizeFiltered = np.bincount(data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_idxq'])\n",
    "# Unfiltered Data\n",
    "azav = np.squeeze(data['jungfrau4M/azav_mask1_azav']) # I(q) : 1D azimuthal average of signals in each q bin\n",
    "qbin = data['UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_qbin'] # q bin-size\n",
    "q = data['UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_q'] # q bins \n",
    "qbins = data['UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_qbins'] # q bins\n",
    "userMask = data['UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_userMask'].astype(bool) # User mask for this region\n",
    "qbinSize = np.bincount(data['UserDataCfg/jungfrau4M/azav_mask1__azav_mask1_idxq'])\n",
    "# Other Data\n",
    "matrix_q = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_matrix_q'].reshape(8,512,1024) # Q values J4M shaped\n",
    "matrix_phi = data['UserDataCfg/jungfrau4M/azav_mask0__azav_mask0_matrix_phi'].reshape(8,512,1024) # phi valyes J4M shaped\n",
    "xrayOn = data['evr/code_137'].astype(bool)  # xray on events\n",
    "xrayOn2 = data['lightStatus/xray'].astype(bool)  # xray on events\n",
    "laserOn = data['lightStatus/laser'].astype(bool)  # xray on events\n",
    "jungfrau_sum = data['Sums/jungfrau4M_calib']  # Total Jungfrau detector counts summed in a run\n",
    "#jungfrau_sum = data['Sums/jungfrau4M_calib_thresADU1']   # Total Jungfrau detector counts with Thresholds added, summed in a run \n",
    "x = data['UserDataCfg/jungfrau4M/x'] # coordinates of Jungfrau detector x,y,z\n",
    "y = data['UserDataCfg/jungfrau4M/y']\n",
    "z = data['UserDataCfg/jungfrau4M/z'] \n",
    "\n",
    "cmask = data['UserDataCfg/jungfrau4M/cmask'].astype(bool) # Mask for detector created \n",
    "run_indicator = data['run_indicator'] # run indicator for each shot\n",
    "# dg3 = data['ipm_dg3/sum']    # downstream diode x-ray intensity\n",
    "# pressure = data['epicsAll/gasCell_pressure']  # pressure in gas cell\n",
    "xray_energy = data['gas_detector/f_11_ENRC']   # xray energy from gas detector (not calibrated to actual values)\n",
    "xray_eV = data['ebeam/photon_energy']    # x-ray energy energy in eV|\n",
    "#dg2Trace = data['CXI-DG2-BMMON-WF/cxi_dg2_bmmon_wf_rebin_data']\n",
    "numPhotons = data['jungfrau4M/Full_thres_sum']\n",
    "spec = data['feeBld/hproj'] # Shot to shot spectrometer\n",
    "dg2traces = data['dg2_traces'][()][:,:,::8] # Dg2 traces, downsampled by a factor of 8\n",
    "dg2Sum = data['ipm_dg2/sum']\n",
    "\n",
    "del data\n",
    "\n",
    "# For some reason we need to offet the data by one. Will this be a problem in later experiments?\n",
    "spec = spec[0:-2];\n",
    "azavFiltered = azavFiltered[1:-1];\n",
    "azav = azav[1:-1];\n",
    "xrayOn = xrayOn[1:-1];\n",
    "xrayOn2 = xrayOn2[1:-1];\n",
    "laserOn = laserOn[1:-1];\n",
    "dg2traces = dg2traces[1:-1]; \n",
    "dg2Sum = dg2Sum[1:-1];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcce205-ee05-4ef5-9697-ed6b1e7d1751",
   "metadata": {},
   "source": [
    "### Ian's DG2 refitting routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7455c44-049e-4d00-b42b-0ca4c8b32a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_intensity_from_traces(traces, scattered_xrays, laserOn,fit_fraction=0.5):\n",
    "    traces_flattened = traces.reshape(traces.shape[0],-1)\n",
    "    fitIdx = (np.random.uniform(size=laserOn.size)<fit_fraction)&(~laserOn)\n",
    "    x, residuals, rank, s = np.linalg.lstsq(traces_flattened[fitIdx],scattered_xrays[fitIdx],rcond=None)\n",
    "   \n",
    "    predicted_xrays = np.matmul(traces_flattened,x)\n",
    "   \n",
    "    return predicted_xrays\n",
    "\n",
    "scattered_xrays = np.sum(azav*qbinSize,axis=-1)\n",
    "scattered_xraysFiltered = np.sum(azavFiltered*qbinSizeFiltered,axis=-1)\n",
    "# scattered_xrays = np.sum(data['jungfrau4M/azav_azav'],axis=-1)\n",
    "# plt.figure()\n",
    "# for i in range(5):|\n",
    "#     plt.plot(traces[i,0,:]+1000*i)\n",
    "# plt.show()\n",
    "predicted_xrays = fit_intensity_from_traces(dg2traces,scattered_xrays,laserOn)\n",
    "\n",
    "plt.hist2d(dg2Sum[~np.isnan(dg2Sum)],scattered_xrays[~np.isnan(dg2Sum)],bins=100);\n",
    "plt.title('DG2 Correlation')\n",
    "plt.xlabel('DG2 Sum')\n",
    "plt.ylabel('J4M Sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f82374-0877-4f7f-b701-0ab04c0d4e49",
   "metadata": {},
   "source": [
    "### Filtering out the bad shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffdf2a-aa7b-442c-a743-b8c0fd311480",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "integration_cutoff = 0.1\n",
    "scattering_cutoff = 0.02\n",
    "##########\n",
    "int_spec = spec.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(int_spec/int_spec.max(),bins=100);\n",
    "plt.axvline(integration_cutoff,color='r',linestyle='--')\n",
    "plt.title('XRT Spectrum Sum Histogram')\n",
    "plt.xlabel('Fraction of Maximum')\n",
    "plt.ylabel('Counts')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(scattered_xrays/scattered_xrays.max(),bins=100)\n",
    "plt.axvline(scattering_cutoff,color='r',linestyle='--')\n",
    "plt.title('J4M Sum Histogram')\n",
    "plt.xlabel('Fraction of Maximum')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "# Doing the actual filtering\n",
    "goodSpecIdx = (int_spec/int_spec.max()>integration_cutoff) & (xrayOn2) & (~laserOn) & (scattered_xrays/scattered_xrays.max()>scattering_cutoff) & (~np.isnan(dg2Sum))\n",
    "specGood = spec[goodSpecIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee4b4a-8e6f-413a-ba17-f342527fa824",
   "metadata": {},
   "source": [
    "### Ghost imaging analysis for finding the spectrometer curve in the unfiltered region (This one takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54fcff-31a2-43c9-b95a-7570169b6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-binning the spectrometer data on a shot-to-shot basis\n",
    "specGood2 = specGood[:,500:1600]; # Cutting off spectrometer values\n",
    "###############\n",
    "N=100 # New amount of bins. (original is 1100)\n",
    "################\n",
    "total_shots = specGood2.shape[0];\n",
    "original_bins = specGood2.shape[1];\n",
    "if original_bins % N != 0: # See if the new amount of bins are good\n",
    "    raise ValueError(\"Number of original bins must be divisible by N.\")\n",
    "delta_N = specGood2.shape[1] // N; # Bin size\n",
    "\n",
    "\n",
    "# Preallocate the rebinned spectrum\n",
    "specGoodRebin = np.zeros((total_shots, N))\n",
    "\n",
    "# Perform the rebinning\n",
    "for i in range(total_shots):\n",
    "    for j in range(N):\n",
    "        sidx = j * delta_N\n",
    "        eidx = (j + 1) * delta_N\n",
    "        specGoodRebin[i, j] = np.sum(specGood2[i, sidx:eidx])\n",
    "F_bright, residuals, rank, s = np.linalg.lstsq(specGoodRebin, scattered_xrays[goodSpecIdx], rcond=None)\n",
    "plt.plot(F_bright)\n",
    "plt.title('XRT Spectrometer Response Curve')\n",
    "plt.xlabel('Energy Coordinate')\n",
    "plt.ylabel('Multiplicitave Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c27c2b-c32a-4d89-8e5b-71db5ce6132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "specCorrected = np.multiply(specGoodRebin,F_bright)\n",
    "integratedSpecCorrected=specCorrected.sum(axis=1);\n",
    "plt.figure(figsize=[12,5]);\n",
    "plt.subplot(1,2,1)\n",
    "counts, xedges, yedges, im = plt.hist2d(specGoodRebin.sum(axis=1),scattered_xrays[goodSpecIdx],100); # The counts variable will be used later.\n",
    "plt.xlabel('Spectrometer Response');\n",
    "plt.ylabel('J4M Sum');\n",
    "plt.title('Before XRT Ghost-Imaging Correction')\n",
    "rcoeff = scipy.stats.pearsonr(specGoodRebin.sum(axis=1),scattered_xrays[goodSpecIdx])\n",
    "plt.text(0.1,0.8,f'Pearson r coeff: {rcoeff.statistic:.5f}',\n",
    "         fontsize=12,fontweight='bold',transform=plt.gca().transAxes,ha='left',color='White')\n",
    "plt.subplot(1,2,2)\n",
    "counts, xedges, yedges, im = plt.hist2d(integratedSpecCorrected,scattered_xrays[goodSpecIdx],100); # The counts variable will be used later.\n",
    "plt.xlabel('Spectrometer Response');\n",
    "plt.ylabel('J4M Sum');\n",
    "plt.title('After XRT Ghost-Imaging Correction')\n",
    "rcoeff = scipy.stats.pearsonr(integratedSpecCorrected,scattered_xrays[goodSpecIdx])\n",
    "plt.text(0.1,0.8,f'Pearson r coeff: {rcoeff.statistic:.5f}',\n",
    "         fontsize=12,fontweight='bold',transform=plt.gca().transAxes,ha='left',color='White')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba163d-a3b8-43ae-9ac7-b18e74880999",
   "metadata": {},
   "source": [
    "### Now to do the same ghost imaging but to apply the spectrometer filter function and take a look a the filtered section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f318dd-8b90-425d-88b5-bc79583d0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numShots, numEbins = specGoodRebin.shape\n",
    "numQbins = azavFiltered.shape[1]\n",
    "\n",
    "# Solve for F(E, q) using least squares\n",
    "F_dim, residuals, rank, s = np.linalg.lstsq(specGoodRebin, azavFiltered[goodSpecIdx], rcond=None)\n",
    "\n",
    "# F_dim now has shape (100, numQbins), representing energy vs. q dependence\n",
    "\n",
    "plt.pcolormesh(qbinsFiltered,np.arange(101), F_dim, shading='auto', cmap='viridis')\n",
    "plt.clim(-0.0000000001, 0.000000001)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"q\")\n",
    "plt.ylabel(\"Energy bins\")\n",
    "plt.title(\"Filter Function F(E, q)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc3d0c-81f5-42f8-8ab3-48b33cce3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "specCorrectedFiltered = np.multiply(specCorrected,F_dim.sum(axis=1))\n",
    "integratedSpecCorrectedFiltered=specCorrectedFiltered.sum(axis=1);\n",
    "plt.figure(figsize=[12,5]);\n",
    "plt.subplot(1,2,1)\n",
    "counts, xedges, yedges, im = plt.hist2d(specCorrected.sum(axis=1),scattered_xraysFiltered[goodSpecIdx],100); # The counts variable will be used later.\n",
    "plt.xlabel('Spectrometer Response');\n",
    "plt.ylabel('Filtered J4M Sum');\n",
    "plt.title('Before Zn edge Correction')\n",
    "rcoeff = scipy.stats.pearsonr(specCorrected.sum(axis=1),scattered_xraysFiltered[goodSpecIdx])\n",
    "plt.text(0.1,0.8,f'Pearson r coeff: {rcoeff.statistic:.5f}',\n",
    "         fontsize=12,fontweight='bold',transform=plt.gca().transAxes,ha='left',color='White')\n",
    "plt.subplot(1,2,2)\n",
    "counts, xedges, yedges, im = plt.hist2d(integratedSpecCorrectedFiltered,scattered_xraysFiltered[goodSpecIdx],100); # The counts variable will be used later.\n",
    "plt.xlabel('Spectrometer Response');\n",
    "plt.ylabel('Filtered J4M Sum');\n",
    "plt.title('After Zn edge Correction')\n",
    "rcoeff = scipy.stats.pearsonr(specCorrectedFiltered.sum(axis=1),scattered_xraysFiltered[goodSpecIdx])\n",
    "plt.text(0.1,0.8,f'Pearson r coeff: {rcoeff.statistic:.5f}',\n",
    "         fontsize=12,fontweight='bold',transform=plt.gca().transAxes,ha='left',color='White')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43eef8-c1fd-4580-8a0c-e9a13c011114",
   "metadata": {},
   "source": [
    "### Picking a threshold for the spectrometer cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543ff6d-5284-4b33-9165-7e9753fa5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageSpectrum = np.mean(specCorrected,axis=0) # Taking the average of the spectra for the selected runs\n",
    "spectrumCutoff = 50\n",
    "plt.plot(averageSpectrum) # Plot the spectrum\n",
    "plt.axvline(spectrumCutoff,color='r',linestyle='--') # Visualize the cutoff\n",
    "plt.title('Average Pulse Spectrum')\n",
    "plt.xlabel('Energy Coordinate (arb)')\n",
    "plt.ylabel('Intensity (arb)')\n",
    "plt.show()\n",
    "print(f'Cutoff = {spectrumCutoff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a833d-3d94-4a87-9517-5acdfb0f76e5",
   "metadata": {},
   "source": [
    "### Calculating the peak ratios via the spectrometer readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18a5a7-6186-43f3-9d4f-030683d9aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_int = specCorrected[:,0:spectrumCutoff].sum(axis=1)\n",
    "I2Ratio = probe_int / integratedSpecCorrected\n",
    "I1Ratio = 1 - I2Ratio\n",
    "\n",
    "plt.figure(figsize=[10,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(I1Ratio,bins=100);\n",
    "plt.title('I1 Ratio')\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Counts')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(I2Ratio,bins=100);\n",
    "plt.title('I2 Ratio')\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a90aa-8e8c-44cc-a663-9d84aadc91b4",
   "metadata": {},
   "source": [
    "### Indicating the data which is used for the linear analysis (low dg2 reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f4f34-c86d-4d15-b601-fffa5bd6bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg2Mask = (xrayOn2) & (~laserOn) & (scattered_xrays/scattered_xrays.max()>scattering_cutoff) & (~np.isnan(dg2Sum));\n",
    "###\n",
    "dg2Cutoff = 0.2\n",
    "###\n",
    "dg2SumGood = dg2Sum[dg2Mask]\n",
    "plt.hist(dg2SumGood/dg2SumGood.max(),bins=100);\n",
    "plt.axvline(dg2Cutoff,color='r',linestyle='--')\n",
    "\n",
    "\n",
    "dg2Low = dg2SumGood/dg2SumGood.max() < dg2Cutoff;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bd6fd-935e-4c96-9e27-d466e39d6b5a",
   "metadata": {},
   "source": [
    "### Looking at the total nonlinearity as a function of the dg2 reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4d27b-5a7a-4a53-a636-be9f97b06dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges (you can adjust the number of bins)\n",
    "num_bins = 10  # Adjust as needed\n",
    "bin_edges = np.linspace(dg2SumGood.min(), dg2SumGood.max(), num_bins + 1)\n",
    "\n",
    "# Digitize dg2Sum to get bin indices\n",
    "bin_indices = np.digitize(dg2SumGood, bin_edges) - 1  # Adjust for zero-based indexing\n",
    "\n",
    "# Initialize an array to store averaged normAzav\n",
    "binned_means = np.zeros(num_bins)\n",
    "\n",
    "normParameter = 'highq'\n",
    "\n",
    "for i in range(num_bins):\n",
    "    if i==0:\n",
    "        refMask = bin_indices == i  # Get indices belonging to this bin\n",
    "        if normParameter == 'dg2':\n",
    "            linearRefSumNorm = (np.sum(azav[dg2Mask][refMask]*qbinSize,axis=1)/dg2SumGood[refMask]).mean(axis=0)\n",
    "        elif normParameter == 'highq':\n",
    "            linearRefSumNorm = (np.sum(azav[dg2Mask][refMask]*qbinSize,axis=1)/azav[dg2Mask][refMask][:,60:-1].sum(axis=1)).mean(axis=0)\n",
    "    tempMask = bin_indices == i  # Get indices belonging to this bin\n",
    "    if np.any(tempMask):  # Check if bin is not empty\n",
    "        if normParameter == 'dg2':\n",
    "            binned_means[i] = 100*(np.mean((azav[dg2Mask][tempMask]*qbinSize).sum(axis=1)/dg2SumGood[tempMask], axis=0)-linearRefSumNorm)/linearRefSumNorm\n",
    "        elif normParameter == 'highq':\n",
    "            binned_means[i] = 100*(np.mean((azav[dg2Mask][tempMask]*qbinSize).sum(axis=1)/azav[dg2Mask][tempMask][:,60:-1].sum(axis=1), axis=0)-linearRefSumNorm)/linearRefSumNorm\n",
    "plt.plot(binned_means,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a20fd1-b1e8-42b3-b669-058d04cabdd9",
   "metadata": {},
   "source": [
    "### Looking at the q and intensity dependence of the total nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4364d-2988-4726-8031-2449e454e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define bin edges (you can adjust the number of bins)\n",
    "num_bins = 10  # Adjust as needed\n",
    "bin_edges = np.linspace(dg2SumGood.min(), dg2SumGood.max(), num_bins + 1)\n",
    "\n",
    "# Digitize dg2SumGood to get bin indices\n",
    "bin_indices = np.digitize(dg2SumGood, bin_edges) - 1  # Adjust for zero-based indexing\n",
    "\n",
    "# Initialize an array to store averaged normAzav\n",
    "binned_means = np.zeros((num_bins, azav.shape[1]))\n",
    "\n",
    "normParameter = 'highq'\n",
    "\n",
    "for i in range(num_bins):\n",
    "    tempMask = bin_indices == i  # Get indices belonging to this bin\n",
    "    if np.any(tempMask):  # Check if bin is not empty\n",
    "        if normParameter == 'dg2':\n",
    "            norm_factor = dg2SumGood[tempMask][:, np.newaxis]  # Reshape to (N,1) for broadcasting\n",
    "            mean_value = np.mean((azav[dg2Mask][tempMask] * qbinSize) / norm_factor, axis=0)\n",
    "        elif normParameter == 'highq':\n",
    "            norm_factor = azav[dg2Mask][tempMask][:, 60:-1].sum(axis=1, keepdims=True)  # Reshape for broadcasting\n",
    "            mean_value = np.mean((azav[dg2Mask][tempMask] * qbinSize) / norm_factor, axis=0)\n",
    "        \n",
    "        if i == 0:\n",
    "            linearRefSumNorm = mean_value  # Store reference for normalization\n",
    "\n",
    "        # Normalize using the first bin's mean as reference\n",
    "        binned_means[i] = 100 * (mean_value - linearRefSumNorm) / linearRefSumNorm\n",
    "\n",
    "# **Plot the data using a color plot**\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(binned_means, aspect='auto', cmap='viridis', extent=[0, azav.shape[1], bin_edges[0], bin_edges[-1]], origin='lower')\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(im, label=\"Normalized Mean (%)\")\n",
    "plt.clim(1,-15)\n",
    "# Labels and Title\n",
    "plt.xlabel(\"q Index\")\n",
    "plt.ylabel(\"dg2 Sum Bins\")\n",
    "plt.title(\"Binned Averages Normalized to First Bin (Color Map)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb119c1-6df6-4196-a1c4-3194b2e85851",
   "metadata": {},
   "source": [
    "### Extracting coeffs from the filtered section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10395f3-7849-42c0-99b9-2bbe875680b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1 = I1Ratio*dg2Sum[goodSpecIdx]\n",
    "I2 = I2Ratio*dg2Sum[goodSpecIdx]\n",
    "X = np.column_stack([I1*I2,I2,I2**2])\n",
    "model = LinearRegression()\n",
    "model.fit(X, scattered_xraysFiltered[goodSpecIdx])\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(f\"coeff_I1I2 = {coefficients[0]:.4f}, coeff_I2 = {coefficients[1]:.4f}, coeff_I2**2 = {coefficients[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7a1ce-59fc-4dc9-b057-79fe97531d36",
   "metadata": {},
   "source": [
    "### Extracting coeffs from the unfiltered section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee21b5-9abd-404c-9a79-eaef51145d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack([I1*I2,I2,I2**2,I1**2,I1])\n",
    "model = LinearRegression()\n",
    "model.fit(X, scattered_xrays[goodSpecIdx])\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(f\"coeff_I1I2 = {coefficients[0]:.4f}, coeff_I2 = {coefficients[1]:.4f}, coeff_I2**2 = {coefficients[2]:.4f}, coeff_I1**2 = {coefficients[3]:.4f}, coeff_I1 = {coefficients[4]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
